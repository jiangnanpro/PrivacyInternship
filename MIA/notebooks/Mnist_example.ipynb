{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership Attack to Keras Model of MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T10:16:38.416924Z",
     "start_time": "2021-05-17T10:16:19.333919Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import dataset_loader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T10:16:40.385882Z",
     "start_time": "2021-05-17T10:16:38.430162Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T10:16:41.771669Z",
     "start_time": "2021-05-17T10:16:40.393676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download mnist dataset \n",
    "if(\"mnist.pkl.gz\" not in os.listdir(\".\")):\n",
    "    !wget http://deeplearning.net/data/mnist/mnist.pkl.gz\n",
    "\n",
    "# if you have it somewhere else, you can comment the lines above\n",
    "# and overwrite the path below\n",
    "mnist_path = \"./mnist.pkl.gz\"\n",
    "\n",
    "# the dataset contains 3 splits (train/dev/test),\n",
    "# each one containing two vectors (pixels and classes)\n",
    "(x_train, y_train), (x_test, y_test), (x_reserve, y_reserve) = dataset_loader.load_mnist(mnist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T10:16:41.779250Z",
     "start_time": "2021-05-17T10:16:41.773617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 50000\n",
      "Test samples: 10000\n",
      "Reserve Sample: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Train samples:', len(x_train))\n",
    "print('Test samples:', len(x_test))\n",
    "print('Reserve Sample:', len(x_reserve))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to split the data into 2 disjoints sets:\n",
    "+ One to train the target model\n",
    "+ The other to use as data from the same distribution to train our shadow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:15:27.561746Z",
     "start_time": "2021-05-12T17:15:27.489051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Train samples: 25000\n",
      "Target Test samples: 5000\n",
      "Attack Train samples: 25000\n",
      "Attack Test samples: 5000\n"
     ]
    }
   ],
   "source": [
    "x_target_train, x_attack_train, y_target_train, y_attack_train = train_test_split(x_train, y_train, test_size=0.5)\n",
    "x_target_test, x_attack_test, y_target_test, y_attack_test = train_test_split(x_test, y_test, test_size=0.5)\n",
    "\n",
    "print('Target Train samples:', len(x_target_train))\n",
    "print('Target Test samples:', len(x_target_test))\n",
    "print('Attack Train samples:', len(x_attack_train))\n",
    "print('Attack Test samples:', len(x_attack_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:15:29.316258Z",
     "start_time": "2021-05-12T17:15:29.298935Z"
    }
   },
   "outputs": [],
   "source": [
    "x_target_train = torch.from_numpy(x_target_train).float()\n",
    "y_target_train = torch.from_numpy(y_target_train).long()\n",
    "\n",
    "x_target_test = torch.from_numpy(x_target_test).float()\n",
    "y_target_test = torch.from_numpy(y_target_test).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:28:11.652629Z",
     "start_time": "2021-05-12T17:28:11.622735Z"
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    # the constructor, parameters are self-documented by their name :)\n",
    "    # input_dim: in our case it will be the size of a single input image\n",
    "    # hidden_dim: the hidden representation dim\n",
    "    # output_dim: the number of class, in our case there are 10 digits\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_ratio=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.proj1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.proj2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        hid = self.proj1(batch)\n",
    "        hid = F.relu(hid)\n",
    "        hid = self.dropout(hid)\n",
    "        \n",
    "        return self.proj2(hid)\n",
    "    \n",
    "\n",
    "    def predict_proba(self,batch):\n",
    "        prob = self.forward(batch)\n",
    "        prob = torch.sigmoid(prob)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:29:07.940332Z",
     "start_time": "2021-05-12T17:28:12.123954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\t 14961.449994564056 \t / dev precision:\t 0.9206\n",
      "1 :\t 6963.051434755325 \t / dev precision:\t 0.94\n",
      "2 :\t 5320.120601654053 \t / dev precision:\t 0.951\n",
      "3 :\t 4315.609936118126 \t / dev precision:\t 0.9568\n",
      "4 :\t 3607.6701641082764 \t / dev precision:\t 0.9626\n",
      "5 :\t 3072.0257781147957 \t / dev precision:\t 0.9666\n",
      "6 :\t 2662.556899189949 \t / dev precision:\t 0.9674\n",
      "7 :\t 2352.8966025710106 \t / dev precision:\t 0.9688\n",
      "8 :\t 2061.4534645676613 \t / dev precision:\t 0.9708\n",
      "9 :\t 1850.823802471161 \t / dev precision:\t 0.9724\n",
      "10 :\t 1669.0346898138523 \t / dev precision:\t 0.9718\n",
      "11 :\t 1462.948995679617 \t / dev precision:\t 0.9722\n",
      "12 :\t 1287.850188717246 \t / dev precision:\t 0.9724\n",
      "13 :\t 1158.0128458440304 \t / dev precision:\t 0.974\n",
      "14 :\t 1056.6941581964493 \t / dev precision:\t 0.9738\n",
      "15 :\t 968.188546076417 \t / dev precision:\t 0.974\n",
      "16 :\t 864.2930233031511 \t / dev precision:\t 0.9742\n",
      "17 :\t 765.0761844813824 \t / dev precision:\t 0.9728\n",
      "18 :\t 737.971402220428 \t / dev precision:\t 0.974\n",
      "19 :\t 644.2588673681021 \t / dev precision:\t 0.9754\n",
      "20 :\t 622.191763073206 \t / dev precision:\t 0.9738\n",
      "21 :\t 543.8582305461168 \t / dev precision:\t 0.974\n",
      "22 :\t 491.9449747055769 \t / dev precision:\t 0.9746\n",
      "23 :\t 444.71766973286867 \t / dev precision:\t 0.9742\n",
      "24 :\t 405.2711576670408 \t / dev precision:\t 0.975\n",
      "25 :\t 422.579185616225 \t / dev precision:\t 0.9756\n",
      "26 :\t 378.0472768805921 \t / dev precision:\t 0.9754\n",
      "27 :\t 360.9084912315011 \t / dev precision:\t 0.976\n",
      "28 :\t 345.88261248357594 \t / dev precision:\t 0.9752\n",
      "29 :\t 300.7297478094697 \t / dev precision:\t 0.9756\n",
      "30 :\t 274.5684312470257 \t / dev precision:\t 0.9764\n",
      "31 :\t 306.8658218383789 \t / dev precision:\t 0.9748\n",
      "32 :\t 263.87799780489877 \t / dev precision:\t 0.9754\n",
      "33 :\t 237.09393340349197 \t / dev precision:\t 0.976\n",
      "34 :\t 231.56935654766858 \t / dev precision:\t 0.9748\n",
      "35 :\t 253.937864985317 \t / dev precision:\t 0.975\n",
      "36 :\t 238.4360787756741 \t / dev precision:\t 0.975\n",
      "37 :\t 224.4969623312354 \t / dev precision:\t 0.9762\n",
      "38 :\t 256.99528642371297 \t / dev precision:\t 0.976\n",
      "39 :\t 197.901355529204 \t / dev precision:\t 0.9774\n",
      "40 :\t 213.20272471010685 \t / dev precision:\t 0.976\n",
      "41 :\t 195.57318275421858 \t / dev precision:\t 0.9766\n",
      "42 :\t 182.7069600019604 \t / dev precision:\t 0.9756\n",
      "43 :\t 179.71795039530843 \t / dev precision:\t 0.9746\n",
      "44 :\t 163.3786928243935 \t / dev precision:\t 0.9752\n",
      "45 :\t 149.70044979080558 \t / dev precision:\t 0.9754\n",
      "46 :\t 171.10740239638835 \t / dev precision:\t 0.9758\n",
      "47 :\t 184.86589220166206 \t / dev precision:\t 0.9736\n",
      "48 :\t 167.79346407577395 \t / dev precision:\t 0.9772\n",
      "49 :\t 151.6316945636645 \t / dev precision:\t 0.9762\n",
      "50 :\t 171.4792877137661 \t / dev precision:\t 0.9738\n",
      "51 :\t 136.3133840188384 \t / dev precision:\t 0.9758\n",
      "52 :\t 150.46084720268846 \t / dev precision:\t 0.9768\n",
      "53 :\t 158.14906807709485 \t / dev precision:\t 0.9754\n",
      "54 :\t 136.72190799936652 \t / dev precision:\t 0.9772\n",
      "55 :\t 142.1202443651855 \t / dev precision:\t 0.9768\n",
      "56 :\t 132.85953950835392 \t / dev precision:\t 0.9752\n",
      "57 :\t 117.25233629904687 \t / dev precision:\t 0.9746\n",
      "58 :\t 148.98055234504864 \t / dev precision:\t 0.9772\n",
      "59 :\t 147.2921864911914 \t / dev precision:\t 0.9762\n",
      "60 :\t 164.33725951984525 \t / dev precision:\t 0.976\n",
      "61 :\t 157.9177150633186 \t / dev precision:\t 0.9778\n",
      "62 :\t 165.60804166831076 \t / dev precision:\t 0.9734\n",
      "63 :\t 111.85663789696991 \t / dev precision:\t 0.9744\n",
      "64 :\t 117.04285320360214 \t / dev precision:\t 0.9772\n",
      "65 :\t 133.48211993649602 \t / dev precision:\t 0.9754\n",
      "66 :\t 113.43659405969083 \t / dev precision:\t 0.9756\n",
      "67 :\t 92.01302032312378 \t / dev precision:\t 0.9774\n",
      "68 :\t 85.37489922717214 \t / dev precision:\t 0.9776\n",
      "69 :\t 125.19432453624904 \t / dev precision:\t 0.9758\n",
      "70 :\t 105.01944348309189 \t / dev precision:\t 0.9762\n",
      "71 :\t 119.2502670972608 \t / dev precision:\t 0.977\n",
      "72 :\t 107.52577620651573 \t / dev precision:\t 0.9782\n",
      "73 :\t 100.82537937629968 \t / dev precision:\t 0.9764\n",
      "74 :\t 94.82430728897452 \t / dev precision:\t 0.9774\n",
      "75 :\t 104.03385746409185 \t / dev precision:\t 0.9776\n",
      "76 :\t 147.46728825196624 \t / dev precision:\t 0.9768\n",
      "77 :\t 110.15615694830194 \t / dev precision:\t 0.978\n",
      "78 :\t 81.42945516016334 \t / dev precision:\t 0.9756\n",
      "79 :\t 91.36540520074777 \t / dev precision:\t 0.976\n",
      "80 :\t 99.89269429387059 \t / dev precision:\t 0.9772\n",
      "81 :\t 81.12822058959864 \t / dev precision:\t 0.977\n",
      "82 :\t 104.5387600781396 \t / dev precision:\t 0.977\n",
      "83 :\t 119.6199967795983 \t / dev precision:\t 0.9782\n",
      "84 :\t 109.18246975773945 \t / dev precision:\t 0.978\n",
      "85 :\t 89.93029398843646 \t / dev precision:\t 0.9758\n",
      "86 :\t 105.12251961883157 \t / dev precision:\t 0.9774\n",
      "87 :\t 99.21194845438004 \t / dev precision:\t 0.977\n",
      "88 :\t 74.58727376052411 \t / dev precision:\t 0.978\n",
      "89 :\t 97.99385746225016 \t / dev precision:\t 0.9788\n",
      "90 :\t 96.68997794901952 \t / dev precision:\t 0.978\n",
      "91 :\t 109.87954920018092 \t / dev precision:\t 0.9756\n",
      "92 :\t 123.58515453781001 \t / dev precision:\t 0.9756\n",
      "93 :\t 91.03081053541973 \t / dev precision:\t 0.9772\n",
      "94 :\t 75.20240985136479 \t / dev precision:\t 0.9772\n",
      "95 :\t 94.16540629323572 \t / dev precision:\t 0.9774\n",
      "96 :\t 101.47762359073386 \t / dev precision:\t 0.977\n",
      "97 :\t 111.06710935337469 \t / dev precision:\t 0.9758\n",
      "98 :\t 69.32687208952848 \t / dev precision:\t 0.9756\n",
      "99 :\t 100.96926290512783 \t / dev precision:\t 0.9782\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "batch_size = 128\n",
    "target_model = Classifier(28*28, 200, 10)\n",
    "\n",
    "optimizer = torch.optim.Adam(target_model.parameters())\n",
    "\n",
    "all_epoch_losses = list()\n",
    "all_epoch_accuracies = list()\n",
    "for epoch in range(n_epoch):\n",
    "    # we keep track of the loss at each epoch\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    target_model.train() # set the network in train mode (i.e. enable dropout)\n",
    "    \n",
    "    # loop over the data\n",
    "    for i in range(0, x_target_train.shape[0], batch_size):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        batch = x_target_train[i:i+batch_size]\n",
    "\n",
    "        logits = target_model(batch)\n",
    "        #print(logits[0])\n",
    "        #print(y_target_train[0])\n",
    "        loss = F.cross_entropy(\n",
    "            logits,\n",
    "            y_target_train[i:i+batch_size],\n",
    "            reduction=\"mean\"\n",
    "        )\n",
    "        \n",
    "        epoch_loss += loss.item() * batch.shape[0]\n",
    "        \n",
    "        loss.backward() # compute the gradient\n",
    "        optimizer.step() # update parameters of the model\n",
    "        \n",
    "    # at the end of each epoch, we eval on the dev data\n",
    "    target_model.eval()\n",
    "    n_dev_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, x_target_test.shape[0], batch_size):\n",
    "            batch = x_target_test[i:i+batch_size]\n",
    "            logits = target_model(batch)\n",
    "            \n",
    "            # compute the class of maximum weight for each sample,\n",
    "            # look at the documentation of argmax!\n",
    "            # pred shape: (n samples,)\n",
    "            pred = logits.argmax(1)\n",
    "            \n",
    "            # compare prediction with gold classes\n",
    "            n_dev_correct += (pred == y_target_test[i:i+batch_size]).sum().item()\n",
    "    \n",
    "    all_epoch_losses.append(epoch_loss)\n",
    "    all_epoch_accuracies.append(n_dev_correct / y_target_test.shape[0]) \n",
    "    print(\n",
    "        epoch, \":\\t\",\n",
    "        epoch_loss,# / len(train_data[0]),\n",
    "        \"\\t / dev precision:\\t\",\n",
    "        n_dev_correct / y_target_test.shape[0],\n",
    "        flush=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:29:10.739019Z",
     "start_time": "2021-05-12T17:29:10.705083Z"
    }
   },
   "outputs": [],
   "source": [
    "res = target_model.predict_proba(x_target_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:29:11.231056Z",
     "start_time": "2021-05-12T17:29:11.211144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3350760e-13 5.3045220e-12 7.1035950e-09 1.0000000e+00 8.5169825e-17\n",
      " 2.5854537e-01 8.5350814e-21 2.5143623e-09 7.4798223e-11 5.2484854e-08]\n"
     ]
    }
   ],
   "source": [
    "print(res[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Shadow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:29:13.681267Z",
     "start_time": "2021-05-12T17:29:13.674601Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from mblearn import ShadowModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:29:17.916750Z",
     "start_time": "2021-05-12T17:29:17.890873Z"
    }
   },
   "outputs": [],
   "source": [
    "shadow_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "train_op = tf.optimizers.Adam(1e-4)\n",
    "shadow_model.compile(optimizer=train_op,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:37:48.348464Z",
     "start_time": "2021-05-12T17:35:48.997030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622ad661447944db9e56e47b2225a8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "shm = ShadowModels(x_attack_train,\n",
    "                   y_attack_train,\n",
    "                   n_models=20,\n",
    "                   target_classes=10,\n",
    "                   learner=shadow_model,\n",
    "                   epochs=100,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:40:44.496859Z",
     "start_time": "2021-05-12T17:40:44.324221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f64f0522898>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_attack_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Attack models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:40:46.291739Z",
     "start_time": "2021-05-12T17:40:46.282203Z"
    }
   },
   "outputs": [],
   "source": [
    "from mblearn import AttackModels\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:40:46.748757Z",
     "start_time": "2021-05-12T17:40:46.729509Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_attack = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T14:10:46.416421Z",
     "start_time": "2021-05-12T14:10:46.395592Z"
    }
   },
   "outputs": [],
   "source": [
    "attacker = AttackModels(target_classes=10, attack_learner=rf_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T14:10:56.110694Z",
     "start_time": "2021-05-12T14:10:47.833115Z"
    }
   },
   "outputs": [],
   "source": [
    "attacker.fit(shm.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack for a signal class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:42:11.437317Z",
     "start_time": "2021-05-12T17:42:11.362695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873109243697479"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=5)\n",
    "\n",
    "K = 8\n",
    "class_label = shm.results[:,-2]\n",
    "\n",
    "rf.fit(shm.results[:,:-2][class_label == K], shm.results[:,-1][class_label == K])\n",
    "\n",
    "pr = rf.predict(shm.results[:,:-2][class_label == K])\n",
    "accuracy_score(pr,shm.results[:,-1][class_label == K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:42:11.933067Z",
     "start_time": "2021-05-12T17:42:11.917296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6251874062968515"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prr = rf.predict(X_final_test[y_final_test[0] == K])\n",
    "\n",
    "accuracy_score(prr,Labels_test[y_final_test[0] == K])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:42:13.819113Z",
     "start_time": "2021-05-12T17:42:13.765327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0.])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:42:15.729256Z",
     "start_time": "2021-05-12T17:42:15.704495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012448132780082987"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(prr,Labels_test[y_final_test[0] == K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:42:17.093097Z",
     "start_time": "2021-05-12T17:42:17.075666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(prr,Labels_test[y_final_test[0] == K])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create attack test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T13:13:28.805510Z",
     "start_time": "2021-05-12T13:13:28.798469Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct a set mix up training set and attack set\n",
    "# feed the set to the target model to get the predict vectors\n",
    "# feed these vectors to the attack model to get the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:07:42.418519Z",
     "start_time": "2021-05-12T17:07:42.265223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In samples: 2500\n",
      "Out0 samples: 2500\n",
      "Out1 samples: 1000\n",
      "Out2 samples: 1000\n"
     ]
    }
   ],
   "source": [
    "_, x_in_test, _, y_in_test = train_test_split(x_target_train, y_target_train, test_size=0.1)\n",
    "_, x_out0_test, _, y_out0_test = train_test_split(x_attack_train, y_attack_train, test_size=0.1)\n",
    "_, x_out1_test, _, y_out1_test = train_test_split(x_test, y_test, test_size=0.1)\n",
    "_, x_out2_test, _, y_out2_test = train_test_split(x_reserve, y_reserve, test_size=0.1)\n",
    "\n",
    "print('In samples:', len(x_in_test))\n",
    "print('Out0 samples:', len(x_out0_test))\n",
    "print('Out1 samples:', len(x_out1_test))\n",
    "print('Out2 samples:', len(x_out2_test))\n",
    "\n",
    "x_final_test = np.vstack((x_in_test, x_out0_test, x_out1_test, x_out2_test))\n",
    "\n",
    "y_in_test = y_in_test.reshape(-1,1)\n",
    "y_out0_test = y_out0_test.reshape(-1,1)\n",
    "y_out1_test = y_out1_test.reshape(-1,1)\n",
    "y_out2_test = y_out2_test.reshape(-1,1)\n",
    "\n",
    "y_final_test = np.vstack((y_in_test, y_out0_test, y_out1_test, y_out2_test)).reshape(1,-1)\n",
    "\n",
    "Labels_test = np.vstack((np.ones_like(y_in_test),np.zeros_like(y_out0_test),np.zeros_like(y_out1_test),np.zeros_like(y_out2_test)))\n",
    "\n",
    "\n",
    "X_final_test = target_model.predict_proba(torch.from_numpy(x_final_test).float()).detach().numpy()\n",
    "\n",
    "#Final_test = np.hstack((X_final_test,y_final_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:08:24.458043Z",
     "start_time": "2021-05-12T17:08:24.007520Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_prob = attacker.predict(shm.results[:,:-2],shm.results[:,-2].astype(int),batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The shadow model's preformance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:06:35.471091Z",
     "start_time": "2021-05-12T17:06:35.335133Z"
    }
   },
   "outputs": [],
   "source": [
    "result = shm.results[:,:-2]\n",
    "\n",
    "label_results = []\n",
    "for i in range(result.shape[0]):\n",
    "    label_results.append(list(result[i]).index(max(result[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T17:06:35.919379Z",
     "start_time": "2021-05-12T17:06:35.887710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9368092263334935"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_results = np.array(label_results)\n",
    "\n",
    "accuracy_score(label_results,shm.results[:,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T14:35:41.641996Z",
     "start_time": "2021-05-12T14:35:41.625952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4831091898815242"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = predict_prob[:,0] < predict_prob[:,1]\n",
    "predict = predict.astype(int)\n",
    "\n",
    "accuracy_score(shm.results[:,-1][:], predict[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T13:14:29.465886Z",
     "start_time": "2021-05-12T13:14:29.274196Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_prob = attacker.predict(X_final_test,y_final_test[0],batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T13:16:08.023506Z",
     "start_time": "2021-05-12T13:16:08.014896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55, 0.45],\n",
       "       [0.48, 0.52],\n",
       "       [0.48, 0.52],\n",
       "       ...,\n",
       "       [0.46, 0.54],\n",
       "       [0.56, 0.44],\n",
       "       [0.41, 0.59]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T13:14:32.092196Z",
     "start_time": "2021-05-12T13:14:32.073337Z"
    }
   },
   "outputs": [],
   "source": [
    "predict = predict_prob[:,0] > predict_prob[:,1]\n",
    "predict = predict.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T16:52:31.750811Z",
     "start_time": "2021-05-12T16:52:31.703981Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [24984, 7000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-293-adc5b4d0608b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     \"\"\"\n\u001b[1;32m   2229\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m     \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 320\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [24984, 7000]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "cross_entropy = log_loss(Labels_test, predict)\n",
    "accuracy = accuracy_score(Labels_test, predict)\n",
    "\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
